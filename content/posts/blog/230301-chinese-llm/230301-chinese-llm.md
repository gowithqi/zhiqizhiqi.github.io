---
title: "中文 LLM 之路(1/2)"
date: 2023-03-04T11:30:03+00:00
# weight: 1
# aliases: ["/first"]
tags: ["LLM"]
# author: ["Me", "You"] # multiple authors

draft: false

description: "在全球以英文为主的 LLM 研发和应用浪潮中，中文社区的 LLM 之路在哪"
# canonicalURL: "https://canonical.url/to/page"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: true
---

本文围绕“中文 LLM 之路”展开一系列思考和论述。

1. 需求：中文社区需要一个专门的 LLM 模型么？如果需要，其特殊性体现在哪？
2. 技术：怎么做？哪些大模块？哪些挑战？如何应对？Milestone 是什么？
3. 研究：通往 AGI 之路？
4. 资源：需要多少钱？需要多少人？需要多少时间？需要多少卡？
5. 竞争：面对大厂？面对创业公司？全球化？
6. 商业：长期目标是什么？短期目标是什么？路径是什么？和技术研发阶段的关系是什么？


显然需要展开的内容实在太多，本文暂时先只关注偏技术的内容，即覆盖**需求**、**技术**和**研究**三个维度的内容，剩余的维度单独写一篇文章来进行讨论

## 1. 需求：政治经济主导高科技领域产业格局

考虑到这个问题的复杂程度，如下的论述大概率是有局限性的，我会持续不断地完善这部分的信息收集和思考。

从过去的历史来看，至少中国市场的特点和政治经济的格局两大要素影响了核心产业在中国是否存在独立的可能性
- 中国市场规模大，这种规模效应容易产生针对中国市场具体情况定制的产品和服务，例如本地生活在中美两地的差异。另外一方面，中国的人口结构和收入结构也有特殊性，AI 改善生产效率的商业价值和发达国家不同
- 中美竞争大背景下的政治经济要素在最近 3~5 年更是主导了若干产业在中国的发展，纯粹的经济模型对产业链格局演化的影响程度逐步被科技含金量所代替，越是前沿的科技越是要“自主可控”。究其本质，暴力是国家间关系的最基础要素，“战场上得不到的东西，谈判桌上也休想得到”，科学技术和暴力是互相成就的。

在宏观经济学没有能力全面论述的情况下，LLM 在人工智能的最前沿也基本决定了其在中国市场“自主可控”的出身。当然，对于实际的商业路径上，也必须围绕中国市场的特点。

## 2. 技术：只是“抄”和工程化么？
对于中文 LLM 的技术之路，大致可以分成如下三个大的步骤，如果是从零开始大概 18 个月：
- **step-1-复现 SOTA**：重点是将算法和训练系统推进到 SOTA 水平。目前以英文为主的 LLM 工作层出不穷，并且有非常全面的详细信息来确认，难点在于高效训练系统的搭建以及 large scale training debug 方法论&技巧。
- **step-2-中文 LLM**：在 SOTA 的算法和训练系统上，重点解决数据和 Evaluation 系统两大模块的问题。不幸的是，这两个环节对于中文来说，开源社区的成果并不丰富。例如，对于数据来说，中文高质量数据天生短缺如何解决？已有的互联网文本中如何去除低质量内容？对于 Evaluation 系统来说更是难题，相对于层出不穷的英文 NLP Downstream Tasks and Dataset，中文的公开测试集有些捉襟见肘（不仅仅是多样性不够丰富，而且距离最前沿不够近），例如 [CUGE](http://cuge.baai.ac.cn/pdf/CUGE.pdf) / [CLUE](https://www.cluebenchmarks.com/) / [MUGE](https://tianchi.aliyun.com/muge)，这些够么？例如，中文 CoT(chain-of-thought) 能力的测试集在哪里？
- **step-3-DemoApp**：在有足够好的 LLM 后，还需要解决产品定义、应用(Alignment) 和 (option) 推理效率问题，以推出让用户直接可感知的 Demo 应用。对于产品定义来说，在中文社区内，最好的 demo 形式是 chat 么？应用算法 finetune 过程中，势必需要将标注体系构建起来（偷懒调用 chatgpt 接口或许是“饮鸠止渴”）。最后，如果不小心 DemoApp 过于火爆，推理效率的问题也是不得不提上日常的事项。

如上三个步骤，也仅仅是中文 LLM 技术之路的 “**A 轮阶段**” ，可预见的未来至少还包括：
- B 轮阶段：技术继续推动的同时进行产品化
  - 继续推动技术，这里的方向很多，后面专门阐述
  - 提升产品体验直至 PMF ，至少要解决推理成本在产品财务模型上可接受、特定场景算法性能可用和好用的问题；
- C 轮阶段：商业化 Scale ；上云，例如 PaaS 层 PMF ；

本 section 暂时重点讨论 **A 轮阶段** 的内容，上文阐述的三个步骤中每个步骤研发的重点模块都不相同，这也直接影响了资源引入的节奏

| step | 算法  | 训练系统 | 训练数据 | Evaluation 系统 | 应用(Alignment) | 推理效率 |
|  ----  | :-:  | :-:  | :-:  |  :-: | :-: | :-: |
| step-1-复现 SOTA  | √ | √  | x | x | x | x |
| step-2-中文 LLM |  √ | √  | √ | √ | x | x |
| step-3-DemoApp |  √ | √  | √ | √ | √ | √ |

### 2.1 step-1-复现 SOTA：Power Law 曲线的对齐是关键，同时开源社区的“免费供给”越来越多
对于复现 SOTA 来说，主要的挑战是算法和训练系统，次要挑战是训练数据模块。虽然也涉及 Eval 系统的工作，这部分更接近确定性的软件工程工作（设计框架可以 scalable 集成更多的测试集），所以懂机器学习训练的不错的软件架构师即可做好。

**算法**是公开资料披露最为详细的部分，代码和论文中有非常详细的阐述，按理来说是非常容易复现的。但是 **model debug 的难度随着 scale 上升会极具上升**，例如在训练周期长达 60 天的 256 卡的训练任务到第 30 天时 loss 开始随机出现 NaN ，这个问题该如何高效的着手？任何的改动都触发从头训练进行验证么？如果不是，从最近一个“**正常**”的 checkpoint 开始 apply 调整是否可行（如何验证某个 checkpoint 是**正常** 的呢）？任何 large scale 上出现的异常状态几乎都面临尝试成本极高的问题。某种视角下，这部分的经验或 knowhow 可能是算法中极其重要但又不是广为熟知的要素。

**训练系统**从整体来看，有硬件和软件两个部分。
- 硬件部分包含 GPU 选型、服务器配置、机房网络设置。这里需要在配置硬件时就对训练时的计算、访存、传输之间的关系进行分析，不要出现 8*A100 的豪华 GPU 组合配置一个 10G 网卡的尴尬情况。另外，虽然今天 LLM 训练似乎 80GB A100 已经是个标配，但芯片创业公司的影响力不容忽视，谁知道哪天 Jim Keller 的 Tenstorrent 在训练芯片上丢出个吊打 NV 的东西。
- 软件部分中，开源项目很多，例如算子优化中 [xFormers](https://github.com/facebookresearch/xformers) 中提供若干高效的 fused cuda 实现（其他如 [flash-attention](https://github.com/HazyResearch/flash-attention))，并行计算中 [ColossalAI](https://github.com/hpcaitech/ColossalAI) 给出的 Tensor Parallel 以及计算传输的调度。但相对于这些，**更需要动态看待开源社区的发展（层出不穷的小模块）**，在架构上做出非常好的抽象，使得可以源源不断的从开源社区获益（反之，在大量历史债的代码上往往需要很大代价集成新的开源模块，甚至是无法做到）。

此步骤中，核心的 metric 是 power law 曲线的趋势能够对齐，如果资金充裕，那么额外花钱训练 100B 量级参数的 SOTA 模型是个更加保险的举措（虽然经济上很不值）。然而，随着开源社区日益活跃，算法和训练系统两大模块中会有越来越多的子集可以“**免费**”获得。做极端一些的设想，假设某个团队直接将训练代码和模型全部开源([LLaMA](https://scontent.xx.fbcdn.net/v/t39.8562-6/333078981_693988129081760_4712707815225756708_n.pdf?_nc_cat=108&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=ov6yTHfLfNQAX9g7O_Z&_nc_ht=scontent.xx&oh=00_AfBKmKCfvfjEKu8IDou4FkQnQQ0X8mUYBvi46XpFg90aZw&oe=6403C422) )，那么是否意味着中文 LLM 的门槛就显著下降了呢？目前来看，很有可能不是这样的，这也是 step-2 需要攻坚的部分。

### 2.2 step-2-中文 LLM：中文训练数据和中文 Eval 系统将是技术团队差异化的主要维度
当以英文为主的 SOTA LLM 模型向中文迁移时，一方面训练数据需要进行调整，公开数据中虽然是 multi-lingual，但这对中文来说距离最优还相去甚远；另一方面是 Evaluation 系统的适配，度量中文 LLM 在具体任务上的算法性能是否是现有几个公开的中文 NLP Task or Dataset 就足够的呢？

**中文训练数据**中最常见的问题是中文高质量数据远远少于英文的问题如何解决，甚至部分学术领域几乎只有英文数据（即零和一的差异）。我们是期待模型能够从英文数据中泛化到中文么（即在 loss 或训练数据设计上进行改进）？还是考虑利用翻译模块来进行辅助（如果是的，那么是训练数据中将全部英文翻译为中文，还是推理时将中文翻译为英文）？甚至是考虑放弃解决这个问题（接受高质量内容就是用英文表达的社会性规律）？这个问题思考和实践的深入程度或许是中文 LLM 研发质量的重要标志之一。

另外，如何度量数据的质量也是个需要想清楚的问题。在有完备评测系统时，至少在不考虑代价时可以通过 ablation study 来评价，而糟糕的事情在于对于中文 LLM 来说评测能力还差距很远，那么此时研发人员主观的评价显得更加重要，这里可以引出两个值得探讨的问题
- 如何设计 heuristic 的策略来自动化的找出高质量的数据？英文高质量数据的特征是否能够帮助自动化找出中文高质量的数据？LM 本身 inference 时的 entropy 是否有潜在帮助的可能？
- 如何主观标注数据的质量？哪些维度需要被考虑，informative? truthfulness? ...

回到数据量，另一个思路是，中文社区高度发达的短视频是否可以作为文本数据的重要补充呢？Openai Whisper 是否也是用来撬动英文大量播客、视频数据的杠杆呢？

**Evaluation 系统**是个更大的问题，本质上是我们如何评测一个 open domain 模型的性能。即使在英文社区，**评价 LLM 性能也是个未收敛的问题**，若干学术工作在解决一个问题的同时往往要伴随构建一个新的测试集（也就是说尚存的公开测试集不足以评价算法提升），也就是说放眼全球的学术圈，评测 LLM 的系统仍然处在不断完善的过程中。回到中文社区，数据集 release 的速度显然不够快，中文也不是各个学术工作的首选语言，这意味着中文 LLM 的评测系统需要很多硬投入，考虑到 research 的全球属性（构建中文测试集并不会额外增加 research credit，内生的积极性是远远不足的），**等待社区构建中文测试集和等死也差不多了**。这个问题的复杂度足以单独展开一篇文章来阐述，简单来说，一方面需要从 query 产生的过程来解构数据的分布，另一方面是模型的能力角度来构建对应的测试集。


### 2.3 step-3-DemoApp：标注体系比算法更难？

在上述两个步骤已经基本解决的时候，需要设计一个有**说服力**的 DemoApp，一方面是足够有用或者有趣（吸引足够的用户），另一方面也需要证明技术的能力。

首先是产品设计，参考 openai 的历程，似乎 chat 这种形式对用户的吸引力大得多，那么结合中国特点的 app 形式是啥呢？或许是一个**可以分享的 chat app**，用户可以将槽点或惊艳轻松的分享到朋友圈（或者其他社交平台），chatgpt 的分享机制做的还不够好。

其次是应用 Alignment，这里涉及到标注整套流程的搭建和 RLHF 算法的实现，两件事都并不容易，且似乎容易被轻视。
- 标注流程：看似简单但实际上极其复杂和困难，所有认真看过 [InstructGPT](https://openai.com/research/instruction-following) 论文的人很容易被其标注的复杂度和难度所震惊（复杂的标注说明、高频的标注员和算法工程师的迭代、标注员的培训和质检等）。这里包含问题的定义（怎样让标准更加清晰）、标注员的筛选/培训、标注过程的质量监控（生成时任务如何自动化评价“正确率”），以及支持上述过程的标注工具。注：最近海天瑞声股价涨上天，难道缺的是标注员和传统的标注工具么？
  - 偷懒的手段是调用 chatgpt api 获取近乎无穷的 alignment 数据，这是**难以拒绝的慢性毒药**！
- SFT -> RLHF：RL 训练的不稳定和 alignment tax 两件事说明这个模块 tuning 出合理的算法性能也要有若干坑要踩。但随着开源社区的推进，这部分的难度也会越来越小（[trlx](https://github.com/CarperAI/trlx)）。

在上述两个子模块本身的难度以外，如何知道自己在中文上做对了也是个重要问题，这个部分显然没有 SOTA 结果可以作为参考，是否作对了完全需要自身团队的独立判断。

最后是个幸福的烦恼，如果出现需要优化推理效率的情况，那么至少说明 DemoApp 没有失败，用户和请求很多。除了 HPC 的极致优化以外，大概率需要算法和工程联合优化，这意味着在 step-1 和 step-2 时对网络结构的选择就要兼顾算法性能和处理效率。


### 2.4 更长期的技术体系（2~3 年）：ChatGPT 是 2012 年的 AlexNet，现有技术缺陷其实“不值一提”
上述内容仍然只是着眼于 18 个月的周期的事情，而星辰大海之路又怎会止步于此呢。当着眼于更长期时，chatgpt 证明了 GPT-3 所带来的范式转变，这与 2012 年 AlexNet 让世人知道 deep learning 类似。新的大坑中当然有太多可以改进的事情。

#### 2.4.1 现有 LLM 技术方向：该做的事情老老实实做掉
- 信息或知识的可控性（Alignment）的能力
  - RLHF Alignment 演进
  - 模型 explicit memory 机制，信息的实时且可控
- 更低的训练和推理成本：**在现有框架 scale up 为收敛之前，成本的下降就是性能的提升**
  - 模型 continue learning 的能力，如何利用已经训练好的 Large Model，而不是每次 from scratch
  - 推理成本的下降
- 更强的算法性能和小样本学习能力
  - Inductive Bias 优化
    - Proxy Task：更合适（比 LM）的挖掘数据内生结构的任务是什么？
    - Prompt：如何 task driven 的找出最合适的 Prompt？CoT 怎么更 systematic 优化？
    - 模型结构：transformer 上更多小改动的优化（虽然 transformer 整体比较稳定，过去两年仍然诞生了若干目前还算有用的改动）？transformer 之后的下一个“超级结构”是啥？
  - 更大规模：对人类文明的内容“learning”更广更深
    - Seq Len：不断长度，从O(N**2)下降到O(n)，更进一步使用 explicit memory 来增加输入长度
    - 模型：引入 MoE 机制，进一步 x100 倍(GPT-2 到 GPT-3 规模增加了 100 倍）规模到 10T 参数量级
    - 数据：音频和视频中的文本数据？利用 LLM Inference（即 LLM 和 LLM 进行 chat，接近于无穷）的数据？利用逻辑体系的公理来自动化的生成数据？
- 框架
  - 生成器+判别器的模式：先验来自于评价好坏总是比生成容易。在相同的技术水平下，更容易获得一个好的判别器，那么对生成器进行 runtime sampling 和判别器的 rescoring，是否能稳定且持续的提升性能呢？
  - Self-Play（引发质变点）：如何让 LLM 帮助 LLM 提升（例如使用 RL 框架进行训练，或者大量 sampling inference 数据，进行打分找出高质量数据）？
  - 引入更多 API：补充 LLM 基础能力缺失（例如复杂数值计算），以及补充 report bias 等
  - Multi-Modal：在输入侧进一步提升模型的通用性，在输出上做到和人类相同

#### 2.4.2 现有 LLM 迭代效率：高昂的验证成本使得向最优点的前进无比缓慢
- **验证效率**：LLM 极高的训练成本使得验证 idea 的有效性极其昂贵，此项成本的优化程度几乎约等于整个领域的进展速度
- 数据体系：有用户持续使用来贡献数据以及算法团队处理的 **Data Engine！**

#### 2.4.3 更 Foundation 的要素：信仰之力
- Scale！：General Framework 下不断冲击工程极限，榨干数据、算力的价值，Emergent Ability 随之而来。
- 超高人才密度！1+1+1+...+1 >> N




## 3. 研究：建设性的 AGI 之路

通往 AGI 之路何在？在具体回答这个问题之前，先尝试阐述几个关于 AGI 定义和理解的观点
1. **AGI 不是 0 到 1 的突变，而是逐步提升的过程**，极端化的定义 AGI 我认为不太有建设性的意义。细化来看我认为**智能有 Generality 和 Performance，两者的乘积是智能的程度**
2. Generality 是通用性，这次 LLM 的突破更多的体现在了这里，大部分的 query 输入时模型似乎都能够给出还可以的结果。从目前来看，在 symbolic task （泛理科问题）上仍然有明显缺陷
3. Performance 是性能，就是在特定任务上是不是足够好，类似于 AlphaGo 能够比最好的人类棋手更强。
4. 过去 10 年 deep learning 的蓬勃发展使得在很多具体 task 上 performance 足够好了（例如各类游戏、人脸识别等），但**从来没有一个算法（或者一个通用的技术框架）在通用性上有显著的突破，这也是为什么从 research 的角度 LLM 激动人心的原因，即在通用性上的巨大推进**。

### 3.1 AGI 路径：Self-Play 的 LLM 引爆下个智能高峰？
![AGI路径](/GP.png)

如上图，从 Generality 和 Performance 两个要素来 plot 智能，尝试将历史和对未来的预测进行总结
- 过去 10 年 deep learning 技术的进展在若干具体任务上的 performance 快速提升，几乎在所有模式识别的任务上都能够和人类水平相当，部分任务（如人脸识别）甚至远远超过人类；虚拟游戏领域也几乎如此，类似于下棋、Dota 和星际争霸等游戏机器也几乎都可以 beat 人类最好选手。从技术的角度来看，这些超越人类智能水平的成功我会归因为两点
  - **Self-Play RL**：基于定义清晰的目标（也就是 loss 或者 reward），在 RL 理论框架内算法能够不断尝试（计算）在目标上获得更好的水平，直至人类在对应目标上也远远不如 AI 的水平
  - **远远超过人类的训练数据量**：不论是人脸识别还是游戏，其 AI Model 的训练数据量是远远（~x1000）超过人类的，这种超级“训练量”也使得算法“learn”到人类无法驾驭的细节或者“智能”
- 最近 2~3 年 LLM 的发展在短期极大的牺牲了 Performance 维度的表现，但显著推进了 Generality 的表现（在广度上几乎覆盖了所有人类文明的内容），这是 AI 首次在通用性获得如此巨大的突破。
  - “语言”作为人类交流的媒介，是整个人类文明的载体，也就是智能的“外显”；
  - 超级模型（LLM）的拟合能力使得从“语言”数据的内生结构建模上学习到了其背后的智能，是智能提升通用性的巨大“捷径”；
  - 但之所以是“捷径”，原因在于模型并没有处理智能本身，更像是“人类文明的镜子”，这种模式的一个显而易见的问题是智能无法自我提升和演进。
- 放眼未来，智能在新的 Generality 水平下，再次出现 Performance 的阶跃会是下个智能高峰
  - 弱 Generality 强 Performance：典型例子如 AlphaFold2/AlphaTensor，在特定任务上追求远远超越人类的表现，以此撬动部分领域的巨大发展（如制药）。
  - 强 Generality 中 Performance：在 LLM 的通用性上，进一步追求更强的 Performance，尤其是如何将类似于 AlphaGo 等工作中 RL 的框架引入到 LLM 的训练中。设想一个可以 self-play(或者说 "self talk") 的 LLM ，其智能水平能够不断地自我提升，而不再收到训练数据分布和数量的约束，其智能水平能够到怎样地水平？！

