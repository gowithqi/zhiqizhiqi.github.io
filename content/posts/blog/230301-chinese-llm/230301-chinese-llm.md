---
title: "中文 LLM 之路"
date: 2023-02-28T11:30:03+00:00
# weight: 1
# aliases: ["/first"]
tags: ["LLM"]
# author: ["Me", "You"] # multiple authors

draft: true

description: "在全球以英文为主的 LLM 研发和应用浪潮中，中文社区的 LLM 之路在哪"
# canonicalURL: "https://canonical.url/to/page"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: true
---

本文围绕“中文 LLM 之路”展开一系列思考和论述。

1. 需求：中文社区需要一个专用的 LLM 模型么？
2. 技术：怎么做？哪些大模块？哪些挑战？如何应对？Milestone 是什么？
3. 资源：需要多少钱？需要多少人？需要多少时间？需要多少卡？
4. 竞争：面对大厂？面对创业公司？全球化？
5. 商业：长期目标是什么？短期目标是什么？路径是什么？和技术研发阶段的关系是什么？
6. 研究：通往 AGI 之路？

Research 创业？技术创业？商业模式创业？

## 1. 需求

考虑到这个问题的复杂程度，如下的论述大概率是有局限性的，我会持续不断的完善这部分的信息收集和思考。

从过去的历史来看，至少中国市场和政治经济两大要素影响了核心产业在中国是否存在独立的可能性
- 中国市场规模大，这种规模效应容易产生针对中国市场具体情况定制的产品和服务，例如本地生活在中美两地的差异。另外一方面，中国的人口结构和收入结构也有特殊性，AI 改善生产效率的商业价值和发达国家不同
- 中美竞争大背景下的政治经济要素在最近 3~5 年更是主导了若干产业在中国的发展，纯粹的经济模型对产业链格局演化逐步被科技含金量所代替，越是前沿的科技越是要“自主可控”

在宏观经济学没有能力全面论述的情况下，LLM 以人工智能最前沿的定性似乎也基本决定了其在中国市场“自主可控”的必要性。当然，对于实际的商业路径上，也必须围绕中国市场的特点。

## 2. 技术
对于中文 LLM 的技术之路，大致可以分成如下三个大的步骤，如果是从零开始大概 18 个月：
- **step-1-复现 SOTA**：重点是将算法和训练系统推进到 SOTA 水平。目前以英文为主的 LLM 工作层出不穷，并且有非常全面的详细信息来确认，难点在于高效训练系统的搭建以及 large scale training debug 方法论&技巧。
- **step-2-中文 LLM**：在 SOTA 的算法和训练系统上，重点解决数据和 Evaluation 系统两大模块的问题。不幸的是，这两个环节对于中文来说，开源社区的成果并不丰富。对于数据来说，中文高质量数据天生短缺如何解决，已有数字化内容中如何筛选？对于 Evaluation 系统来说更是难题，相对于层出不穷的英文 NLP Downstream Tasks and Dataset，中文的公开测试集有些捉襟见肘（不仅仅是多样性不够丰富，而且距离最前沿不够近），例如 [CUGE](http://cuge.baai.ac.cn/pdf/CUGE.pdf) / [CLUE](https://www.cluebenchmarks.com/) / [MUGE](https://tianchi.aliyun.com/muge)，这些够么？
- **step-3-DemoApp**：在有足够好的 LLM 后，还需要解决产品定义、应用算法 finetune 和 (option) 推理效率问题，以推出让用户直接可感知的 Demo 应用。对于产品定义来说，在中文社区内，最好的 demo 形式是 chat 么？应用算法 finetune 过程中，势必需要将标注体系构建起来（偷懒调用 chatgpt 接口或许是“饮鸠止渴”）。最后，如果不小心 DemoApp 过于火爆，推理效率的问题也是不得不提上日常的事项。

如上三个步骤，也仅仅是中文 LLM 技术之路的 “**A 轮阶段**” ，可预见的未来至少还包括：
- B 轮阶段：技术继续推动的同时进行产品化
  - 继续推动技术，这里的方向很多，后面专门阐述
  - 提升产品体验直至 PMF ，至少要解决推理成本在产品财务模型上可接受、特定场景算法性能可用和好用的问题；
- C 轮阶段：商业化 Scale ；上云，例如 PaaS 层 PMF ；

本 section 暂时重点讨论 **A 轮阶段** 的内容，上文阐述的三个步骤中每个步骤研发的重点模块都不相同，这也直接影响了资源引入的节奏

| step | 算法  | 训练系统 | 训练数据 | Evaluation 系统 | 应用(Alignment) | 推理效率 |
|  ----  | :-:  | :-:  | :-:  |  :-: | :-: | :-: |
| step-1-复现 SOTA  | √ | √  | x | x | x | x |
| step-2-中文 LLM |  √ | √  | √ | √ | x | x |
| step-3-DemoApp |  √ | √  | √ | √ | √ | √ |

### 2.1 step-1-复现 SOTA
对于复现 SOTA 来说，主要的挑战是算法和训练系统，次要挑战是训练数据模块。虽然也涉及 Eval 系统的工作，这部分更接近确定性的软件工程工作（设计框架可以 scalable 集成更多的测试集），所以懂机器学习训练的不错的软件架构师即可做好。

**算法**是公开资料披露最为详细的部分，代码和论文中有非常详细的阐述，按理来说是非常容易复现的。但是 **model debug 的难度随着 scale 上升会极具上升**，例如在训练周期长达 60 天的 256 卡的训练任务到第 30 天时 loss 开始随机出现 NaN ，这个问题该如何高效的着手？任何的改动都触发从头训练进行验证么？如果不是，从最近一个“**正常**”的 checkpoint 开始 apply 调整是否可行（如何验证某个 checkpoint 是**正常** 的呢）？任何 large scale 上出现的异常状态几乎都面临尝试成本极高的问题。某种视角下，这部分的经验或 knowhow 可能是算法中极其重要但又不是广为熟知的要素了。

**训练系统**从整体来看，有硬件和软件两个部分。
- 硬件部分包含 GPU 选型、服务器配置、机房网络设置。这里需要在配置硬件时就对训练时的计算、访存、传输之间的关系进行分析，不要出现 8*A100 的豪华 GPU 组合配置一个 10G 网卡的尴尬情况。虽然今天 LLM 训练似乎 80GB A100 已经是个标配，但芯片创业公司的影响力不容忽视，谁知道哪天 Jim Keller 的 Tenstorrent 在训练芯片上丢出个吊打 NV 的东西。
- 软件部分包含的内容很多，这里开源项目也很多，例如算子优化中 [xFormers](https://github.com/facebookresearch/xformers) 中提供若干高效的 fused cuda 实现（其他如 [flash-attention](https://github.com/HazyResearch/flash-attention))，并行中 [ColossalAI](https://github.com/hpcaitech/ColossalAI) 给出的 Tensor Parallel 以及计算传输的调度。需要动态看待开源社区的发展（层出不穷的小模块），在架构上做出非常好的抽象，使得可以源源不断的从开源社区获益（在大量历史功能的训练代码上往往无法高效集成新的开源模块，甚至是无法做到）。

此步骤中，核心的 metric 是 power law 曲线的趋势能够对齐，如果资金充裕，那么额外花钱训练100B 量级参数的 SOTA 模型是个更加保险的举措（虽然经济上很不值）。然而，随着开源社区日益活跃，算法和训练系统两大模块中会有越来越多的子集可以“**免费**”获得。做极端一些的设想，假设某个团队直接将训练代码和模型全部开源，那么是否意味着中文 LLM 的门槛就显著下降了呢？目前来看，很有可能不是这样的，这也是 step-2 需要攻坚的部分。

### 2.2 step-2-中文 LLM
当以英文为主的 SOTA LLM 模型向中文迁移时，一方面训练数据需要进行调整，公开数据中虽然是 multi-lingual，但这对中文来说远远不足；另一方面是 Evaluation 系统的适配，度量中文 LLM 在具体任务上的算法性能是否是现有几个公开的中文 NLP Task or Dataset 就足够的呢？

**中文训练数据**中最常见的问题是中文高质量数据远远少于英文的问题如何解决，甚至部分学术领域几乎只有英文数据（即零和一的差异）。我们是期待模型能够从英文数据中泛化到中文么（即在 loss 或训练数据设计上进行改进）？还是考虑利用翻译模块来进行辅助（如果是的，那么是训练数据中将全部英文翻译为中文，还是推理时将中文翻译为英文）？甚至是暂时考虑放弃解决这个问题（接受高质量内容就是用英文表达的社会性规律）？这个问题思考和实践的深入程度或许是中文 LLM 研发质量的重要标志之一。

另外，如何度量数据的质量也是个需要想清楚的问题。在有完备评测系统时，至少在不考虑代价时可以通过 ablation study 来评价，而糟糕的事情在于对于中文 LLM 来说评测能力可能还差距很远，那么此时研发人员主观的评价显得更加重要，这里可以引出两个值得探讨的问题
- 如何设计 heuristic 的策略来自动化的找出高质量的数据？英文高质量数据的特征是否帮助自动化找出中文高质量的数据？LM 本身 inference 时的 entropy 是否有明显的区分效果？
- 如何主观标注数据的质量？哪些维度需要被考虑，informative? truthfullness? ...

回到数据量，另一个思路是，中文社区高度发达的短视频是否可以作为文本数据的重要补充呢？Openai Whisper 是否也是用来撬动英文大量播客、视频数据的杠杆呢？

**Evaluation 系统**是个更大的问题，本质上是我们如何评测一个 open domain 模型的性能。即使在英文社区，评价 LLM 性能也是个未收敛的问题，若干学术工作在解决一个问题的同时往往都要伴随构建一个新的测试集（也就是说尚存的公开测试集不足以评价算法提升），也就是说放眼全球的学术圈，评测 LLM 的系统仍然处在不断完善的过程中。回到中文社区，数据集 release 的速度显然不够快，中文也不是各个学术工作的首选语言，这意味着中文 LLM 的评测系统需要很多硬投入，考虑到 research 的全球属性（构建中文测试集并不会额外增加 research credit，内生的积极性是远远不足的），等待社区构建中文测试集和等死也差不多了。这个问题的复杂度足以单独展开一篇文章来阐述，简单来说，一方面需要从 query 产生的过程来解构数据的分布，另一方面是模型的能力角度来构建对应的测试集。后面有时间会尝试写一篇专题文章。


### 2.3 step-3-DemoApp

在上述两个步骤已经基本解决的时候，需要设计一个有**说服力**的DemoApp，一方面是足够有用或者有趣（吸引足够的用户），另一方面也需要证明技术的能力。

首先是产品设计，参考 openai 的历程，似乎 chat 这种形式对用户的吸引力大得多，那么结合中国特点的 app 形式是啥呢？或许是一个**可以分享的 chat app**，用户可以将槽点或惊艳轻松的分享到朋友圈（或者其他社交平台），chatgpt 的分享机制做的还不够好。

其次是应用 Alignment，这里涉及到标注整套流程的搭建和 RLHF 算法的实现，两件事都并不容易，且似乎容易被轻视。
- 标注流程：看似简单但实际上极其复杂和困难，所有认真看过 [InstructGPT](https://openai.com/research/instruction-following) 论文的人很容易被其标注的复杂度和难度所震惊（复杂的标注说明、高频的标注员和算法工程师的迭代、标注员的培训和质检等）。这里包含问题的定义（怎样让标准更加清晰）、标注员的筛选/培训、标注过程的质量监控（生成时任务如何自动化评价“正确率”），以及支持上述过程的标注工具。注：最近海天瑞声股价涨上天，难道缺的是标注员和传统的标注工具么？
  - 偷懒的手段是调用 chatgpt api 获取近乎无穷的 alignment 数据，这是**难以拒绝的慢性毒药**！
- SFT -> RLHF：RL 训练的不稳定和 alignment tax 两件事说明这个模块也有相当的复杂度。

在上述两个子模块本身的难度以外，如何知道自己做对了也是需要小心定义和观察，这个部分显然没有 SOTA 结果可以作为参考，是否作对了完全需要自身团队的独立判断

最后是个幸福的烦恼，如果出现需要优化推理效率的情况，那么至少说明 DemoApp 没有失败（是否成功可能还需要别的必要条件），用户很多。除了 HPC 的极致优化以外，大概率需要算法和工程联合优化，这意味着在 step-1 和 step-2 时对网络结构的选择就要兼顾算法性能和处理效率。


### 2.4 更长期的技术体系（2~3 年）
上述内容仍然只是着眼于 18 个月的周期的事情，而星辰大海之路又怎会止步于此呢。当着眼于更长期时，技术演进的方向是什么呢？技术迭代的速度如何提升呢？

#### 2.4.1 现有 LLM 技术方向
- 信息或知识的可控性（Alignment）的能力
  - RLHF Alignment 演进
  - 模型 explicit memory 机制，信息的实时且可控
- 更低的训练和推理成本：**在现有框架 scale up 为收敛之前，成本的下降就是性能的提升**
  - 模型 continue learning 的能力，如何利用已经训练好的 Large Model，而不是每次 from scratch
  - 推理成本的下降
- 更强的算法性能和小样本学习能力
  - Inductive Bias 优化
    - Proxy Task：更合适（比 LM）的挖掘数据内生结构的任务是什么？
    - Prompt：如何 task driven 的找出最合适的 Prompt？CoT 怎么更 systematic 优化？
    - 模型结构：transformer 上更多小改动的优化（虽然 transformer 整体比较稳定，过去两年仍然诞生了若干目前还算有用的改动）？transformer 之后的下一个“超级结构”是啥？
  - 更大规模：对人类文明的内容“learning”更广更深
    - 模型：引入 MoE 机制，进一步 x100 倍规模到 10T 参数量级
    - 数据：音频和视频中的文本数据？利用 LLM Inference（即 LLM 和 LLM 进行 chat，接近于无穷）的数据？利用逻辑体系的公理来自动化的生成数据？
  - 框架
    - 生成器 with 判别器的模式：先验来自于评价好坏总是比生成容易。在相同的技术水平下，更容易获得一个好的判别器，那么对生成器进行 runtime sampling 和判别器的 rescore，是否能稳定且持续的提升性能呢？
    - Self-Play（引发质变点）：如何让 LLM 帮助 LLM 提升（例如超大量 sampling inference 数据，进行打分找出高质量数据）？
    - 引入更多 API：补充 LLM 基础能力缺失（例如复杂数值计算），补充 report bias 等
- Multi-Modal！

#### 2.4.2 现有 LLM 迭代效率
- **验证效率**：LLM 极高的训练成本使得验证 idea 的有效性极其昂贵，此项成本的优化程度几乎约等于整个领域的进展速度
- 数据体系：有用户持续使用来贡献数据以及算法团队处理的 Data Engine！

#### 2.4.3 更 Foundation 的要素
- Scale！：General Framework 下不断冲击工程极限，榨干数据、算力的价值，Emergent Ability 随之而来。
- 超高人才密度！1+1+1+...+1 >> N

## 3. 资源
资源上暂时只考虑钱、人、时间、卡*几个维度
| 时间 | 钱 | 人 | 卡 | 目标 | 
| :-: |:-: |:-: |:-: | :- |
| 12 个月 | $12M~$15m | 30 | 100~300\*A100| |
| 24 个月 | 
| 36 个月 | 



## 6. 研究

通往 AGI 之路何在？在具体回答这个问题之前，先尝试阐述几个关于 AGI 定义和理解的观点
1. **AGI 不是 0 突然到 1 的变化，而是逐步提升的过程**，极端化的定义 AGI 我认为不太有建设性的意义。细化来看我会从两个维度评价智能，分别是 Generalization 和 Performance，两者的乘积是智能的程度
2. Generalization 是通用性，这次 LLM 的突破更多的体现在了这里，大部分的 query 输入时模型似乎都能够给出还可以的结果。从目前来看，在 symbolic task （泛理科问题）上仍然有明显缺陷
3. Performance 是性能，就是在特定任务上是不是足够好，类似于 AlphaGo 能够比最好的人类棋手更强。
4. 过去 10 年 deep learning 的蓬勃发展使得在很多具体 task 上 performance 足够好了（例如各类游戏、人脸识别等），这些超越人类的表现主要来自两点：要么是利用 self-play 的 rl 机制进行提升，要么利用远远超过人类的训练数据量。但**从来没有一个算法（或者一个通用的技术框架）在通用性上有显著的突破，这也是为什么从 research 的角度 LLM 激动人心的原因，即在通用性上的巨大推进**。
5. 而接下来在 LLM 的框架上继续向前（比如如何让 chatgpt self-play），AGI 推进的速度会明显加快。

### 6.1 如何推进 Generalization？
### 6.2 如何推进 Performance？






