---
title: "Week-AI-01：LLaMA"
date: 2023-02-28T15:30:03+00:00
# weight: 1
# aliases: ["/first"]
tags: ["Week"]
# author: ["Me", "You"] # multiple authors

draft: true

description: "todo"
# canonicalURL: "https://canonical.url/to/page"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: true
---

## 0. TakeAway


## 1. 前沿技术追踪
- moore's law of intelligence: https://twitter.com/sama/status/1629880171921563649
- Multimodal Chain-of-Thought Reasoning in Language Models
- Colossal-Auto: Unified Automation of Parallelization and Activation Checkpoint for Large-scale Models
- Aligning Text-to-Image Models using Human Feedback

### 1.1 LLaMA：开源 LLM，撬动全球零散算力和脑力资源的杠杆
Meta 汇总 GPT-3 之后近两年所有重要的 LLM 改进，训练了 LLM 模型，规模从 7B 到 65B，在大量 NLP Task 的评测上大部分比 GPT-3 & Chinchilla-70B & PaLM-540B 更好，更重要的是此项工作完成基于公开数据，并且模型会进行开源分享！

**如何实现的？** 
1. 数据：除了广泛被使用的 CommonCrawl & C4 & Wikipedia & Book 之外，还直接使用了 Github & Arxiv & StackExchange，分别对应代码、（各个学科）科学论文和高质量的问答数据。注：这些改动为此项工作后续的实验结果解读增加了很多干扰
2. 网络结构：在原始 transformer 上引入了 pre-normalization（提升训练稳定性）、SwiGLU（提升性能）、Rotary Embeddings（position embedding 改进）。
3. 训练加速：针对 MHA（multi-head attention）实现了更高效的代码（注：xformers 内有对应实现）减少内存和计算；若干 common 操作：forward activation checkpoint（细节在于手动指定层，而不是自动计算的结果，更加快） & 并行 & 计算和传输并行等。
4. 训练效率：在 2048 块 A100 卡上训练 65B 模型，380 tokens/sec/GPU，21 天训练了 1.4T tokens。注：这个结果来看，并不是个昂贵的配置，在实践中，两个月的训练周期仍然在可接受的范畴内，也就是说 512 A100 即可。

**哪些值得注意的实验结果** 作者在大量的任务上进行了测试，其中有几个结果更加值得注意和解读
1. Scale 对算法性能的提升远远没有收敛：一方面是相同规模下的模型，进一步增加 step 数量看上去仍有提升空间，另一方面是进一步提升规模，预计仍然可以提升 downstream task 算法性能。作者也表示：Finally, we plan to release larger models trained on larger pretraining corpora in the future, since we have seen a constant improvement in performance as we were scaling.
2. 训练 loss 的曲线图，可以明显看到更大模型的 loss 曲线更大概率出现更大程度的 loss 异常值，在进一步推进规模时模型训练的稳定性可能会面临更大挑战
3. Natural Question 数据集上，0-shot 显著比之前的算法好（65B vs GPT-3 是 23.8 vs 14.6），这个巨大的区别或许来自训练数据的调整
4. Mathematical reasoning 相关数据集上，Minerva(finetuned by ArXiv and Math Web Pages) 几乎吊打所有 pretrained model。作者并没有解释这里的原因
5. 在 TruthfulQA 上，LLaMA 显著好于 GPT-3，0.57 vs 0.28 of Truthful，0.53 vs 0.25 of Truthful*informative，在作者表示 the rate of correct answers is still low, showing that our model is likely to hallucinate incorrect answers，也就是模型在某些维度上仍然明显不如 GPT-3 上的表现。

**为什么重要？** 模型开源会改变学术界生态，LLM 应用层的研究会爆发，全球更加零散的算力和脑力资源可以投入到这个方向的研究上（而不是超级大组的寡头竞争游戏）。这种学界的变化也会逐步影响到工业界和创业圈子。

**还有哪些问题？** 
1. 详细的分析过程，其中至少包含：1）ablation study 的欠缺，同时 apply 如此多改动，哪些是真的对结果有影响的；2）Error Case Analysis，在具体的 case 上模型呈现出哪些额外的优势或劣势，对这些现象的猜测和归因是什么？
2. Emergent Ability 测试缺失。例如，现有 65B 上有 CoT 能力么？

**ReadMore:** [LLaMA: Open and Efficient Foundation Language Models
](https://scontent.xx.fbcdn.net/v/t39.8562-6/333078981_693988129081760_4712707815225756708_n.pdf?_nc_cat=108&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=ov6yTHfLfNQAX9g7O_Z&_nc_ht=scontent.xx&oh=00_AfBKmKCfvfjEKu8IDou4FkQnQQ0X8mUYBvi46XpFg90aZw&oe=6403C422)


## 2. 技术 idea 方向
- RLHF 意味着什么

## 3. 思考
- RLHF 