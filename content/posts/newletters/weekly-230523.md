---
title: "Week-AI-03：#"
date: 2023-05-22T11:30:03+00:00
# weight: 1
# aliases: ["/first"]
tags: ["Week"]
# author: ["Me", "You"] # multiple authors

draft: true

description: "Desc Text."
# canonicalURL: "https://canonical.url/to/page"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: true
---

偷懒将近两个月，回来写点东西

## 0. TakeAway & 思考

## 1. 前沿技术追踪

## 其他有意思的内容（感谢 ChatPDF）

- [sparse video tube](https://ai.googleblog.com/2023/05/sparse-video-tubes-for-joint-video-and.html) ：google 提出对 video 数据更好的表征，分成三种：image patch & 长时间的 patch & 时间空间均等的 patch。这种 sparse tube 可以让模型 apply 更少的算力对视频进行建模，最终在 something someting v2 （76.1%）和 kinetics-400（90.9%）获得 sota 结果。这引发的思考是真正思考 video 数据的模型时，其 representation 应该是什么？
- [SEAHORSE](https://arxiv.org/pdf/2305.13194.pdf)：96k Summarization 多语言数据集，并且用这个数据集可以训练模型来对模型结果进行打分。deepmind 和 google search 的合作。
- **[SoViT](https://arxiv.org/pdf/2305.13035.pdf)**： scale law for ViT