---
title: "Week-AI-00：ToolFormer; ControlNet"
date: 2023-02-24T11:30:03+00:00
# weight: 1
# aliases: ["/first"]
tags: ["Week"]
# author: ["Me", "You"] # multiple authors

draft: false
description: "机器智能使用工具，猿到人的转变？"
# canonicalURL: "https://canonical.url/to/page"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: true
---































## 1. 前沿技术追踪
### 1.1 ToolFormer： 训练 LLM 使用工具，机器智能发生从猿到人的转变
Meta 的研究人员训练 LLM 去使用 API（a calculator, a Q&A system, a search engine, a translation system, and a calendar），从结果来看，明显补充了 LLM 部分能力的不足。更重要的是，他们给出了一个通用的方法来让模型学习使用任意的工具（API）。从实验结果来看，6.7B GPT-J 模型 with ToolFormer 可以超越 66B OPT 和 175B GPT-3 的算法性能

**什么是 ToolFormer** "a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction."

**内部是如何实现的？** 数据生成的方式：从 plain text 出发，使用 in context 的方式让 LLM 生成若干潜在有用的 API 候选，根据 perplexity 来找出其中有用的 API 候选。将筛选后的 API 融合在原始数据中对模型进行 finetune。若干数据样例
```
Note: The WL will be open on Friday, <API> Calendar() → Today is Thursday, March 9, 2017.
</API> March 10, and Sunday, March 19 for regular hours.

The Nile has an approximate length of <API> QA(What is the approximate length of the Nile?)
→ 6,853 km </API> 6,853 kilometers, the White Nile being its main source.

Os Melhores Escolas em Jersey 2020 <API> MT(Os Melhores Escolas em Jersey) → The Best
Schools in Jersey </API> On this page you can search for Universities, Colleges and Business
schools in Jersey
```

**几点有意思的实验结果** 1）在数学计算和推理的数据上，显著超过了 GPT-3 的性能（ASDiv 14.0->40.4; SVAMP 10.0->29.4; MAWPS 19.8->44.0); 2）在日期相关的任务上构建了推理日期关系的数据集，秒杀 GPT-3（0.8 vs 27.3）3）Scale Law：模型在 775M 大小时才开始能够从使用工具中获益。

**为什么重要** 
1. 方法通用，不依赖大量的人工标注，对 API 的属性没有假设。这意味着可以更加激进的引入 API 弥补 LLM 能力的不足；接下来如何更加交互的引入各类 API 或许会成为专门的研究热点，尤其是其在工具辅助下更加接近人类表现，在应用上更具短期价值，可以小小期待一下超级 RPA 能力。
2. LLM 在特定的 "basic skill" 存在严重缺陷，既为 foundation model 的提升指出潜在方向，也是无比“亲切”的问题，人类在没有工具的情况下，解决问题的能力也显著降低了。同时，引发出 LLM **不需要**具备哪些能力的讨论，我们是否因为期待 LLM 具备太多能力而做了不必要的努力和浪费，甚至牺牲了哪些更需要 LLM 具备的能力
3. 人类祖先学会使用工具促进了从猿到人，30 年过后，又会如何定性今天 LLM 开始学会使用工具呢？

**ReadMore**:[Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/abs/2302.04761)


### 1.2 ControlNet：受控的图片生成，设计师可以响应的需求，“还有谁？！”
Stanford 研究者找到一个低成本让 pretrained diffusion model align to condition 的方法，finetune 的数据量可以在 50k 以内，这也意味着其所需的算力往往也只需要单卡即可。当然此方法也可以泛化到更大量的数据上

**什么是 ControlNet？**  to control pretrained large diffusion models to support additional input conditions

**内部如何实现** 
1. 将 pretrain model 拆分为 “locked copy” 和 “trainable copy”，其目的在于 “The motivation of making such copies rather than directly training the original
weights is to avoid overfitting when dataset is small and to preserve the production-ready quality of
large models learned from billions of images”
2. 在 “lock copy” 网络中每一层的输出增加 “trainable copy” 对输入的“调整”，从某个角度来说，“trainable copy” 针对性的补充 “locked copy” 每层缺少的 condition 信息，这种针对性由 loss 实现
3. 在 “trainable copy” 中引入 zero conv ，其有两点特性，模型初始化时模型 forward 结果与 “locked copy” 完全相同，其次导数并不会为零，这意味着其优化更加容易

**为什么重要**
1. 应用上，交互式的图片生成，2D 设计师的“专业软件和绘画”能力不再有价值，人类设计师最后的护城河是艺术的部分，即对用户、美学和文明的理解
2. 算力需求惊人的少，在 funetune 6k step 前后出现 "the phenomenon of sudden convergence"，即开始能够基本 align 输入的 condition

**还有哪些问题？**
1. 对图片的“修改意见”可能是多种形式的，例如风格迁移较难融合到这个框架中。但目前来看，学界距离一个 general alignment 框架已经不远了
2. 在上一点的基础上，产品上需要能够收集用户修改图片的过程

**ReadMore**: [Adding Conditional Control to Text-to-Image
Diffusion Models](https://arxiv.org/pdf/2302.05543.pdf)


## 2. 思考
- Hierarchical LLM Func：类似于软件世界是一层又一层构建起来的，LLM enabled 能力是否应该层次化呢，软件 2.0 的通用架构真的就是一个 Large Transformer 解决一起问题么？
- 应用层的壁垒更准确来说是“打分器”（而不是泛泛的说是 domain data），也就是说，谁在应用层更知道怎样的结果是“好的”谁更占优势。而目前看到的趋势是 general 图片生成的壁垒会不断降低，及时由 domain 数据来进行 domain image 的生成，这部分的壁垒也明显不够高。
- 是围绕工具还是围绕内容？Adobe 会是柯达（只想卖胶卷）么？
- 先不谈视频生成，GIP 水平的动效设计师是不是在颤抖？
