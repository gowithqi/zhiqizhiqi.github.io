---
title: "Week-AI-02：Pytorch2.0/USM"
date: 2023-03-20T11:30:03+00:00
# weight: 1
# aliases: ["/first"]
tags: ["Week"]
# author: ["Me", "You"] # multiple authors

draft: false

description: "todo"
# canonicalURL: "https://canonical.url/to/page"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: true
---


## 0. TakeAway & 思考

## 1. 前沿技术追踪
### 1.1 Pytorch 2.0：全球免费获赠 1 倍算力！
引入 torch.compile 这个大坑（包含了若干底层技术），DL 开发者以很低的开发成本享受计算效率（榨干硬件）的提升，可以预见未来很长一段时间，整个技术栈仍然会快速发展。另外，针对 transformer 的优化也是值得注意的，尤其是 MHA pytorch2.0 实现，包含了 FlashAttention 和 xFormers 等第三方的实现，开发者可以通过 pytorch 2.0 接口直接支持各种高度优化的 MHA 实现

**torch.compile**
1. 效果：163 个开源模型 93% 可以直接调用 torch.compile，**在 A100 上快 43%；FP32 精度下，快 21%，混合精度下，快 51%** ---> 免费的软件午餐，今年应该不需要买新机器了吧
2. "From day one, we knew the performance limits of eager execution" and "Our key criteria was to preserve certain kinds of flexibility – support for dynamic shapes and dynamic programs which researchers use in various stages of exploration."
3. Part-1 Graph Acquisition：TorchDynamo + AOTAutograd，放弃了若干不合适的尝试（比如"TorchScript, FX tracing, Lazy Tensors."），这些尝试很难在 flexible / user-experience / fast 上都靠谱
    1. TorchDynamo vs TorchScript，在 7000+ Github Pytorch project 中前者可以捕捉到 99% ，而后者只有 50%（而且有很大的 overhead）。TorchDynamo 在 python bytecode 这层进行 hook，获取全部的计算图，也就是说理论上不止适用 pytorch 接口，所有 python 调用都可以进行优化。ReadMore: [TorchDynamo](https://pytorch.org/docs/stable/dynamo/index.html)
    2. AOTAutograd 用来捕捉 bp 计算图，复用了 torch_dispatch ，可以 "capture the backwards pass “ahead-of-time”."
4. Part-2 Graph Lowering：Aten/Prim IR
5. Part-3 Graph Compilation：
    1. TorchInductor enable by Triton，自动将 pytorch model 编译为 GPU 上的 triton 代码或者 cpu 上的 c++/openmp 代码；TorchInductor 核心 IR 只包含 [50 个 op](https://github.com/pytorch/pytorch/blob/master/torch/_inductor/codegen/triton.py)，未来还会进一步扩展；
    2. PrimTorch 定义 250 个左右的 low-level op，适合编译器进行 fuse together 以获得更好的性能

**为什么重要**
1. 免费向全球供给将近 1 倍 GPU 算力，某种程度来说对整个学术界的进展是巨大的推动
2. 平台型软件可以不断供给算力，layer by layer 的分层解耦会不断增加 overhead 吞掉硬件性能；很容易预测的是 compile 的引入使得 pytorch 未来性能提升仍有较大的空间
3. Triton 吃掉 Cuda：以 block 作为编程抽象，相对于 SIMT(single instruct multi-thread) 更加适合 deep learning，开发者在 python 端就可以写出和 hand-written 性能相当的 NN 算子实现。
4. 额外的问题是 pytorch 之上的中间件应该如何设计接口呢？例如 ColossalAI/deepspeed 等 

**ReadMore:** [Pytorch 2.0](https://pytorch.org/blog/pytorch-2.0-release/)

### 1.2 USM：语音识别技术框架收敛，覆盖所有语言
著名的 Google Yonghui Wu 带队（特征是 Large Scale 并且兼顾工程实现和部署）,Google 27 人团队实现 ASR 全面性极强的技术框架，并在多语种的识别性能上比 Whisper 有巨大提升，相对于 2～3 代算法的差异（Err 减少 50%）。

**如何实现的？**
- 训练框架，分成三个阶段，从 self-supervised 到 supervised asr
    - Self-Supervised BEST-RQ(BERT-based Speech pre-training with random projection Quantizer)，80% 算力，12M 小时语音（其中 12M 小时来自 youtube 覆盖 300 种语言；429k 小时来自公开数据集覆盖 51 种语言）
    - Multi Objective Supervised pre-training MOST: 三个训练目标，分别是阶段一中的 BEST-RQ Loss & text-injection & ASR 监督 loss，15% 算力，每个语种 100～10k 监督数据（其中 90k 小时标注数据来自 youtube 覆盖 73 种语言；100k 小时由 NST 生成的英语 pseudo-label 数据；10k 小时英文不同领域的标注数据；10k 小时公开的标注数据覆盖 102 种语言）和 28B sent 文本（覆盖 1140 种语言）。内部有两阶段训练，先将 speech text alignment 训练好，之后在训练全部的 loss
    - Supervised ASR：CTC or LAS 输出，5% 算力，task specific paired data
- 模型 Conformer 2B(32 Layers with 1536D)
- BEST-RQ： Multi-Softmax，预测多组 prob，以此提升训练时的稳定性（这背后有多少坑？）
- Chunck-wise Attention：强行将 seq 分为不相交的多组，attention 只在同一组内的 frame 进行；这种方式也使得模型在 streaming 输入时具备 streaming 输出的能力；这种方式使得长语音在推理时性能可以不下降（但问题是推理时真的有长语音推理的需求么？）
- Text-Injection：设计 text encoder 将文本映射到和语音相同的特征空间，简单来说，可以认为 implicitly 做了语音合成。这使得大量的文本数据可以进行伪 asr 训练（而不是真的需要训练多种语言的语音合成模型）

**重要的实验结果：** SOTA：多语言 ASR 上达到最佳性能并吊打 Whisper，尤其是 USM 用了 90k 小时标注数据（而 Whisper 用了 400k 小时），从提升的幅度来看（多语种上 err 减少 50%）是巨大的提升，差了 2～3 代算法的性能。同时 Scalable，相对于 Wav2Vec 2.0 or W2v-BERT，USM 使用 conformer 可以扩展到 2B 参数量级。

**仍有哪些不足？**
- 数据多样性：大量采用了 youtube 数据是不够好的（在 domain 和语种上可能覆盖的还不错），在其他的数据维度还有明显缺陷（例如远场、电话/网络电话、不同音频编解码格式等）。
- 更加激进的伪标签（NST）数据量，offline 推理（large am combine & large lm ）所带来的性能提升并没有被激进的使用。换句话说，应该在阶段二将阶段一 12M 小时的无 label 数据全部 inference 一遍将其全都在阶段二进行训练
- 模型规模进一步提升，不知道遇到的瓶颈是什么

**为什么重要？**
- 语音识别技术框架收敛：虽然还有一些还不够完善的维度，但从全面性来说重点的问题基本上都覆盖掉了（包括大量数据的自监督训练、大量文本数据帮助语音训练、工程部署的遍历性和流式的支持）
- 语音识别 API 可能也会收敛：语音越来越会成为平台型的技术（因为单个模型的训练成本越来越大），应用开发者不会考虑自己研发
- Unlabeled Data Self Supervised vs Weakly Label Data 的对比是非常重要的问题，作者将主要的算力和数据按照前者的方式进行训练，并在下游任务上获得了非常好的结果。“We believe diverse unlabeled data is more practical to
acquire for building usable ASR for tail languages than weakly labeled data”；而这里值得 debate 的问题是在 offline 可以自动生成更准 label 的情况下，Weakly Label Data 可能是很难被舍弃的。

**ReadMore:** [USM(Universal Speech Model)](https://ai.googleblog.com/2023/03/universal-speech-model-usm-state-of-art.html)

